# ğŸ§¯ Industrial Safety Object Detection using YOLOv8

This repository contains our solution for the BuildWithIndia 2.0 Hackathon organized by SunHacks, where we trained a YOLOv8 model to detect **Fire Extinguishers**, **Tool Boxes**, and **Oxygen Tanks** in industrial environments using computer vision.

---

**ğŸ‘¥ Team**
Team Name: **Codies**
Hackathon: **BuildWithIndia 2.0 (SunHacks) â€“ Duality AI Challenge**

**Team Leader:**

Samarth Sharma â€“ samarth120904@gmail.com

**Team Members:**

Vaibhav Sharma â€“ vaibhavsh0120@gmail.com

Prithvi Singh â€“ prithvis3804@gmail.com

Parth Garg â€“ 2300300100120@ipec.org.in

---

## ğŸš€ Project Overview

The aim of this project is to ensure workplace safety using real-time object detection of essential equipment. By leveraging YOLOv8 and ONNX, our solution can run across various platforms â€” and is optimized for Flutter (mobile) integration.

### ğŸ“Œ Objects Detected:
- ğŸ”¥ Fire Extinguisher
- ğŸ§° Tool Box
- ğŸ§ª Oxygen Tank

---

## ğŸ“Š Final Results

After training and evaluation, the model achieved:

| Class            | Precision | Recall | mAP@0.5 | mAP@0.5:0.95 |
|------------------|-----------|--------|---------|---------------|
| Fire Extinguisher| **1.000** | 0.936  | **0.977** | 0.914 |
| Tool Box         | 0.992     | 0.883  | **0.948** | 0.916 |
| Oxygen Tank      | 0.965     | 0.873  | **0.901** | 0.822 |
| **Overall**      | 0.986     | 0.898  | **0.942** | **0.884** |

> âœ… Model: `YOLOv8m`  
> âœ… Framework: PyTorch + Ultralytics + ONNX

---

## ğŸ“ Folder Structure

```bash

HackWithDelhi2.0/
â”£ ğŸ“ data/              â† âš ï¸ Copy this folder manually from Dataset (see below section)
â”ƒ â”£ ğŸ“ train/
â”ƒ â”ƒ â”£ ğŸ“ images/
â”ƒ â”ƒ â”— ğŸ“ labels/
â”ƒ â”£ ğŸ“ val/
â”ƒ â”ƒ â”£ ğŸ“ images/
â”ƒ â”ƒ â”— ğŸ“ labels/
â”ƒ â”£ ğŸ“ predict/
â”ƒ â”ƒ â”£ ğŸ“ images/
â”ƒ â”ƒ â”— ğŸ“ labels/
â”ƒ â”— ğŸ“„ data.yaml
â”£ ğŸ“ runs/              â† YOLO training logs and result artifacts
â”£ ğŸ“œ Train\_YOLOv8.ipynb â† ğŸ““ Full notebook: training, predicting & exporting
â”£ ğŸ“œ train.py           â† ğŸ” Training script (alternative to notebook)
â”£ ğŸ“œ predict.py
â”£ ğŸ“œ visualize.py       â† If used for metrics/image display
â”£ ğŸ“œ yolo_params.yaml   â† Config file if used
â”£ ğŸ“œ yolov8m.pt         â† Trained model weights
â”£ ğŸ“œ best.onnx          â† Model Exported as ONNX
â”£ ğŸ“œ BuildWithDelhi2.0_Report.pdf â† Final report
â”— ğŸ“œ README.md          â† ğŸ“„ You're here!

```

---

## ğŸ“¦ Dataset

The dataset used in this project is not included in this GitHub repo due to its size (~3.9â€¯GB).  
Please download it from the official source:

ğŸ”— **[Download from Duality (Account Required)](https://falcon.duality.ai/secure/documentation/hackathon?utm_source=hackathon&utm_medium=instructions&utm_campaign=sunhacks)**

### ğŸ“‚ After Downloading:

1. Extract the contents.
2. Copy the entire `data/` folder into the root directory of this repo.
3. Ensure the folder structure looks like this:

---

## ğŸ§  Model Training & Export

All training, validation, and ONNX export steps are documented in:

ğŸ““ `Train_YOLOv8.ipynb`

Exported model:

```bash
runs/detect/train/weights/best.onnx  âœ…
```

---

## ğŸ“± Flutter Integration (via ONNX)

This repo is designed to integrate the exported ONNX model (`best.onnx`) into a mobile app using **Flutter**.

Flutter + ONNX support is still evolving, but you can use it with the help of:

---

## ğŸ“¸ Result Samples

Here are visual examples of how our YOLOv8 model detects objects like fire extinguishers, toolboxes, and oxygen tanks in real-world images.

### ğŸ”¹ Validation Batch Predictions
Visualized predicted labels during validation phase using `val_batch1_labels.jpg`:

![Validation Results](runs/detect/train/val_batch1_labels.jpg)

### ğŸ”¹ Training Batch Samples
Sample training images used by YOLOv8 (`train_batch1.jpg`) showing bounding boxes during model training:

![Training Batch](runs/detect/train/train_batch1.jpg)

## ğŸ“Š Training Metrics

The following plot summarizes the training progress over 50 epochs, including loss curves and accuracy metrics such as precision, recall, and mean Average Precision (mAP):

![Training Results](runs/detect/train/results.png)


> All these visuals are automatically generated and stored in the `runs/detect/train/` directory after training.




